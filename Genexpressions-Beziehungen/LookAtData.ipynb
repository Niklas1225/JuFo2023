{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f645869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74d18bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"gene_ids\": shape (36601,), type \"|O\">"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"var\"][\"gene_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2c9c2dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"APOE4 Status\": shape (1957283,), type \"|i1\">"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"obs\"][\"APOE4 Status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f3e09",
   "metadata": {},
   "source": [
    "<h2>Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541c43cf",
   "metadata": {},
   "source": [
    "![alt text](anndata.svg \"First look at Data-Structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a10228",
   "metadata": {},
   "source": [
    "<h3>Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b299355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"data/SEAAD_MTG_RNAseq_all-nuclei.2022-08-18.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba5d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"indptr\": shape (1957284,), type \"<i8\">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"X\"][\"indptr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed72b914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"indices\": shape (9579432766,), type \"<i8\">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"X\"][\"indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47de38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"APOE4 Status\": shape (1957283,), type \"|i1\">"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"obs\"]['APOE4 Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa3e3b",
   "metadata": {},
   "source": [
    "<h3>List important markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0a156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids = list(map(str.lower, np.array(f[\"var\"][\"gene_ids\"]).astype('U13')))\n",
    "gene_ids = list(np.array(f[\"var\"][\"gene_ids\"]).astype('U13'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb324616",
   "metadata": {},
   "source": [
    "<h4>CSF</h4>\n",
    "Cerebrospinal fluid (CSF) biomarkers: Certain proteins found in cerebrospinal fluid, such as amyloid beta 42 (Aβ42), total tau (T-tau), and phosphorylated tau (P-tau), can serve as biomarkers for Alzheimer's disease. Decreased levels of Aβ42 and increased levels of T-tau and P-tau are associated with the presence of amyloid plaques and neurodegeneration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5311db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CSF3R',\n",
       " 'CSF1',\n",
       " 'CSF2',\n",
       " 'CSF1R',\n",
       " 'ACSF3',\n",
       " 'CSF3',\n",
       " 'ACSF2',\n",
       " 'CSF2RB',\n",
       " 'CSF2RA']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_marker = \"CSF\"\n",
    "res = [i for i in gene_ids if search_marker.lower() in i.lower()]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9850ec4",
   "metadata": {},
   "source": [
    "<h4>PET</h4>\n",
    "Amyloid PET imaging: Positron Emission Tomography (PET) scans using specific radiotracers can detect and measure the accumulation of beta amyloid plaques in the brain. These scans can provide valuable information about the presence and extent of amyloid pathology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe88a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PET100', 'PET117']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_marker = \"PET\"\n",
    "res = [i for i in gene_ids if search_marker.lower() in i.lower()]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff421e84",
   "metadata": {},
   "source": [
    "<h4>APOE</h4>\n",
    "APOE ε4 allele: The APOE gene has different alleles, and the APOE ε4 allele is the most well-known genetic risk factor for late-onset Alzheimer's disease. Carrying one or two copies of the APOE ε4 allele increases the risk of developing the disease. APOE ε4 is associated with increased deposition of beta amyloid in the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa8431ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APOE']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_marker = \"APOE\"\n",
    "res = [i for i in gene_ids if search_marker.lower() in i.lower()]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339585a",
   "metadata": {},
   "source": [
    "<h4>APP</h4>\n",
    "Amyloid Precursor Protein (APP): APP is the precursor protein from which alpha and beta amyloid are derived. Mutations in the APP gene can lead to an increased production of beta amyloid and are associated with early-onset familial Alzheimer's disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57ff0c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRAPPC3',\n",
       " 'PAPPA2',\n",
       " 'TRAPPC12',\n",
       " 'TRAPPC12-AS1',\n",
       " 'APPL1',\n",
       " 'DAPP1',\n",
       " 'TRAPPC11',\n",
       " 'TRAPPC13',\n",
       " 'TRAPPC3L',\n",
       " 'TRAPPC9',\n",
       " 'PAPPA',\n",
       " 'PAPPA-AS2',\n",
       " 'PAPPA-AS1',\n",
       " 'TRAPPC4',\n",
       " 'IAPP',\n",
       " 'APPL2',\n",
       " 'EAPP',\n",
       " 'TRAPPC6B',\n",
       " 'TRAPPC2L',\n",
       " 'TRAPPC1',\n",
       " 'APPBP2',\n",
       " 'TRAPPC8',\n",
       " 'TRAPPC5',\n",
       " 'TRAPPC6A',\n",
       " 'TRAPPC2B',\n",
       " 'APP',\n",
       " 'TRAPPC10',\n",
       " 'TRAPPC2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_marker = \"APP\"\n",
    "res = [i for i in gene_ids if search_marker.lower() in i.lower()]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f878b",
   "metadata": {},
   "source": [
    "so app is also contained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3373461",
   "metadata": {},
   "source": [
    "Inflammatory markers: Chronic inflammation has been implicated in Alzheimer's disease. Biomarkers such as C-reactive protein (CRP), interleukin-6 (IL-6), and tumor necrosis factor-alpha (TNF-α) have been associated with inflammation and neurodegeneration in AD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f29a6ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TNFRSF18',\n",
       " 'TNFRSF4',\n",
       " 'C1QTNF12',\n",
       " 'TNFRSF14-AS1',\n",
       " 'TNFRSF14',\n",
       " 'TNFRSF25',\n",
       " 'TNFRSF9',\n",
       " 'TNFRSF8',\n",
       " 'TNFRSF1B',\n",
       " 'TNFAIP8L2',\n",
       " 'TNFSF18',\n",
       " 'TNFSF4',\n",
       " 'TNFAIP6',\n",
       " 'TNFSF10',\n",
       " 'C1QTNF7',\n",
       " 'C1QTNF3',\n",
       " 'TNFAIP8',\n",
       " 'C1QTNF2',\n",
       " 'TNF',\n",
       " 'TNFRSF21',\n",
       " 'TNFAIP3',\n",
       " 'TNFRSF10B',\n",
       " 'TNFRSF10C',\n",
       " 'TNFRSF10D',\n",
       " 'TNFRSF10A-AS1',\n",
       " 'TNFRSF10A',\n",
       " 'TNFRSF11B',\n",
       " 'TNFSF15',\n",
       " 'TNFSF8',\n",
       " 'C1QTNF4',\n",
       " 'C1QTNF5',\n",
       " 'TNFRSF1A',\n",
       " 'TNFRSF19',\n",
       " 'C1QTNF9B',\n",
       " 'C1QTNF9',\n",
       " 'C1QTNF9-AS1',\n",
       " 'TNFSF11',\n",
       " 'TNFSF13B',\n",
       " 'TNFAIP2',\n",
       " 'TNFAIP8L3',\n",
       " 'C1QTNF8',\n",
       " 'TNFRSF12A',\n",
       " 'TNFRSF17',\n",
       " 'TNFSF12',\n",
       " 'TNFSF13',\n",
       " 'TNFRSF13B',\n",
       " 'TNFAIP1',\n",
       " 'C1QTNF1-AS1',\n",
       " 'C1QTNF1',\n",
       " 'TNFRSF11A',\n",
       " 'TNFAIP8L1',\n",
       " 'TNFSF9',\n",
       " 'TNFSF14',\n",
       " 'TNFRSF6B',\n",
       " 'C1QTNF6',\n",
       " 'TNFRSF13C']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_marker = \"TNF\"\n",
    "res = [i for i in gene_ids if search_marker.lower() in i.lower()]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8d2c034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KCNB1']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_marker = \"KCNB1\"\n",
    "res = [i for i in gene_ids if search_marker.lower() in i.lower()]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff26625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOE4 Status\n",
      "ATAC_Confidently_mapped_read_pairs\n",
      "ATAC_Fraction_of_genome_in_peaks\n",
      "ATAC_Fraction_of_high_quality_fragments_in_cells\n",
      "ATAC_Fraction_of_high_quality_fragments_overlapping_TSS\n",
      "ATAC_Fraction_of_high_quality_fragments_overlapping_peaks\n",
      "ATAC_Fraction_of_transposition_events_in_peaks_in_cells\n",
      "ATAC_Mean_raw_read_pairs_per_cell\n",
      "ATAC_Median_high_quality_fragments_per_cell\n",
      "ATAC_Non-nuclear_read_pairs\n",
      "ATAC_Number_of_peaks\n",
      "ATAC_Percent_duplicates\n",
      "ATAC_Q30_bases_in_barcode\n",
      "ATAC_Q30_bases_in_read_1\n",
      "ATAC_Q30_bases_in_read_2\n",
      "ATAC_Q30_bases_in_sample_index_i1\n",
      "ATAC_Sequenced_read_pairs\n",
      "ATAC_TSS_enrichment_score\n",
      "ATAC_Unmapped_read_pairs\n",
      "ATAC_Valid_barcodes\n",
      "Age at Death\n",
      "Arteriolosclerosis\n",
      "Atherosclerosis\n",
      "Braak\n",
      "Brain Region\n",
      "Brain pH\n",
      "CERAD score\n",
      "Class\n",
      "Class confidence\n",
      "Cognitive Status\n",
      "Donor ID\n",
      "Doublet score\n",
      "Fraction mitochondrial UMIs\n",
      "Fresh Brain Weight\n",
      "GEX_Estimated_number_of_cells\n",
      "GEX_Fraction_of_transcriptomic_reads_in_cells\n",
      "GEX_Mean_raw_reads_per_cell\n",
      "GEX_Median_UMI_counts_per_cell\n",
      "GEX_Median_genes_per_cell\n",
      "GEX_Percent_duplicates\n",
      "GEX_Q30_bases_in_UMI\n",
      "GEX_Q30_bases_in_barcode\n",
      "GEX_Q30_bases_in_read_2\n",
      "GEX_Q30_bases_in_sample_index_i1\n",
      "GEX_Q30_bases_in_sample_index_i2\n",
      "GEX_Reads_mapped_antisense_to_gene\n",
      "GEX_Reads_mapped_confidently_to_exonic_regions\n",
      "GEX_Reads_mapped_confidently_to_genome\n",
      "GEX_Reads_mapped_confidently_to_intergenic_regions\n",
      "GEX_Reads_mapped_confidently_to_intronic_regions\n",
      "GEX_Reads_mapped_confidently_to_transcriptome\n",
      "GEX_Reads_mapped_to_genome\n",
      "GEX_Reads_with_TSO\n",
      "GEX_Sequenced_read_pairs\n",
      "GEX_Total_genes_detected\n",
      "GEX_Valid_UMIs\n",
      "GEX_Valid_barcodes\n",
      "GEX_number_of_reads\n",
      "GEX_sequencing_saturation\n",
      "Gender\n",
      "Genes detected\n",
      "Genome\n",
      "Highest Lewy Body Disease\n",
      "Highest level of education\n",
      "Hispanic\n",
      "Interval from last CASI in months\n",
      "Interval from last MMSE in months\n",
      "Interval from last MOCA in months\n",
      "LATE\n",
      "Last CASI Score\n",
      "Last MMSE Score\n",
      "Last MOCA Score\n",
      "Multiome_Feature_linkages_detected\n",
      "Multiome_Linked_genes\n",
      "Multiome_Linked_peaks\n",
      "NeuN positive fraction on FANS\n",
      "Neurotypical reference\n",
      "Number of UMIs\n",
      "Number of mapped reads\n",
      "Number of multimapped reads\n",
      "Number of reads\n",
      "Number of unmapped reads\n",
      "Organism\n",
      "Overall AD neuropathological Change\n",
      "Overall CAA Score\n",
      "PMI\n",
      "Primary Study Name\n",
      "RIN\n",
      "Race (choice=American Indian\n",
      "Race (choice=Asian)\n",
      "Race (choice=Black\n",
      "Race (choice=Native Hawaiian or Pacific Islander)\n",
      "Race (choice=Other)\n",
      "Race (choice=Unknown or unreported)\n",
      "Race (choice=White)\n",
      "Secondary Study Name\n",
      "Sex\n",
      "Subclass\n",
      "Subclass confidence\n",
      "Supertype\n",
      "Supertype (non-expanded)\n",
      "Supertype confidence\n",
      "Thal\n",
      "Total Microinfarcts (not observed grossly)\n",
      "Total microinfarcts in screening sections\n",
      "Used in analysis\n",
      "Years of education\n",
      "__categories\n",
      "alignment\n",
      "amplified_quantity_ng\n",
      "ar_id\n",
      "avg_size_bp\n",
      "batch_vendor_name\n",
      "bc\n",
      "cell_prep_type\n",
      "exp_component_name\n",
      "exp_component_vendor_name\n",
      "expc_cell_capture\n",
      "experiment_component_failed\n",
      "facs_population_plan\n",
      "library_input_ng\n",
      "library_prep\n",
      "library_prep_pass_fail\n",
      "load_name\n",
      "method\n",
      "pcr_cycles\n",
      "percent_cdna_longer_than_400bp\n",
      "quantification_fmol\n",
      "r1_index\n",
      "rna_amplification\n",
      "rna_amplification_pass_fail\n",
      "sample_id\n",
      "sample_name\n",
      "sample_quantity_count\n",
      "specify other race\n"
     ]
    }
   ],
   "source": [
    "for i in f[\"obs\"].keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "074a5def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141703\n",
      "1004945\n",
      "810635\n"
     ]
    }
   ],
   "source": [
    "cog_status = np.array(f[\"obs\"][\"Cognitive Status\"])\n",
    "print(len(cog_status[cog_status == 0]))\n",
    "print(len(cog_status[cog_status == 1]))#reference\n",
    "print(len(cog_status[cog_status == 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c26d641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88], dtype=int8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(f[\"obs\"][\"Donor ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8250dbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957283"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f[\"obs\"][\"Supertype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c037a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = f[\"obs\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dcd9c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Latino'], dtype='<U6')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(f[\"obs\"][\"Hispanic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a1f18ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOE4 Status\n",
      "ATAC_Confidently_mapped_read_pairs\n",
      "ATAC_Fraction_of_genome_in_peaks\n",
      "ATAC_Fraction_of_high_quality_fragments_in_cells\n",
      "ATAC_Fraction_of_high_quality_fragments_overlapping_TSS\n",
      "ATAC_Fraction_of_high_quality_fragments_overlapping_peaks\n",
      "ATAC_Fraction_of_transposition_events_in_peaks_in_cells\n",
      "ATAC_Mean_raw_read_pairs_per_cell\n",
      "ATAC_Median_high_quality_fragments_per_cell\n",
      "ATAC_Non-nuclear_read_pairs\n",
      "ATAC_Number_of_peaks\n",
      "ATAC_Percent_duplicates\n",
      "ATAC_Q30_bases_in_barcode\n",
      "ATAC_Q30_bases_in_read_1\n",
      "ATAC_Q30_bases_in_read_2\n",
      "ATAC_Q30_bases_in_sample_index_i1\n",
      "ATAC_Sequenced_read_pairs\n",
      "ATAC_TSS_enrichment_score\n",
      "ATAC_Unmapped_read_pairs\n",
      "ATAC_Valid_barcodes\n",
      "Age at Death\n",
      "Arteriolosclerosis\n",
      "Atherosclerosis\n",
      "Braak\n",
      "Brain Region\n",
      "Brain pH\n",
      "CERAD score\n",
      "Class\n",
      "Class confidence\n",
      "Cognitive Status\n",
      "Donor ID\n",
      "Doublet score\n",
      "Fraction mitochondrial UMIs\n",
      "Fresh Brain Weight\n",
      "GEX_Estimated_number_of_cells\n",
      "GEX_Fraction_of_transcriptomic_reads_in_cells\n",
      "GEX_Mean_raw_reads_per_cell\n",
      "GEX_Median_UMI_counts_per_cell\n",
      "GEX_Median_genes_per_cell\n",
      "GEX_Percent_duplicates\n",
      "GEX_Q30_bases_in_UMI\n",
      "GEX_Q30_bases_in_barcode\n",
      "GEX_Q30_bases_in_read_2\n",
      "GEX_Q30_bases_in_sample_index_i1\n",
      "GEX_Q30_bases_in_sample_index_i2\n",
      "GEX_Reads_mapped_antisense_to_gene\n",
      "GEX_Reads_mapped_confidently_to_exonic_regions\n",
      "GEX_Reads_mapped_confidently_to_genome\n",
      "GEX_Reads_mapped_confidently_to_intergenic_regions\n",
      "GEX_Reads_mapped_confidently_to_intronic_regions\n",
      "GEX_Reads_mapped_confidently_to_transcriptome\n",
      "GEX_Reads_mapped_to_genome\n",
      "GEX_Reads_with_TSO\n",
      "GEX_Sequenced_read_pairs\n",
      "GEX_Total_genes_detected\n",
      "GEX_Valid_UMIs\n",
      "GEX_Valid_barcodes\n",
      "GEX_number_of_reads\n",
      "GEX_sequencing_saturation\n",
      "Gender\n",
      "Genes detected\n",
      "Genome\n",
      "Highest Lewy Body Disease\n",
      "Highest level of education\n",
      "Hispanic\n",
      "Interval from last CASI in months\n",
      "Interval from last MMSE in months\n",
      "Interval from last MOCA in months\n",
      "LATE\n",
      "Last CASI Score\n",
      "Last MMSE Score\n",
      "Last MOCA Score\n",
      "Multiome_Feature_linkages_detected\n",
      "Multiome_Linked_genes\n",
      "Multiome_Linked_peaks\n",
      "NeuN positive fraction on FANS\n",
      "Neurotypical reference\n",
      "Number of UMIs\n",
      "Number of mapped reads\n",
      "Number of multimapped reads\n",
      "Number of reads\n",
      "Number of unmapped reads\n",
      "Organism\n",
      "Overall AD neuropathological Change\n",
      "Overall CAA Score\n",
      "PMI\n",
      "Primary Study Name\n",
      "RIN\n",
      "Race (choice=American Indian\n",
      "Race (choice=Asian)\n",
      "Race (choice=Black\n",
      "Race (choice=Native Hawaiian or Pacific Islander)\n",
      "Race (choice=Other)\n",
      "Race (choice=Unknown or unreported)\n",
      "Race (choice=White)\n",
      "Secondary Study Name\n",
      "Sex\n",
      "Subclass\n",
      "Subclass confidence\n",
      "Supertype\n",
      "Supertype (non-expanded)\n",
      "Supertype confidence\n",
      "Thal\n",
      "Total Microinfarcts (not observed grossly)\n",
      "Total microinfarcts in screening sections\n",
      "Used in analysis\n",
      "Years of education\n",
      "__categories\n",
      "alignment\n",
      "amplified_quantity_ng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar_id\n",
      "avg_size_bp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_vendor_name\n",
      "bc\n",
      "cell_prep_type\n",
      "exp_component_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_component_vendor_name\n",
      "expc_cell_capture\n",
      "experiment_component_failed\n",
      "facs_population_plan\n",
      "library_input_ng\n",
      "library_prep\n",
      "library_prep_pass_fail\n",
      "load_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n",
      "pcr_cycles\n",
      "percent_cdna_longer_than_400bp\n",
      "quantification_fmol\n",
      "r1_index\n",
      "rna_amplification\n",
      "rna_amplification_pass_fail\n",
      "sample_id\n",
      "sample_name\n",
      "sample_quantity_count\n",
      "specify other race\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n",
      "/tmp/ipykernel_752472/2537234453.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[i] = np.array(f[\"obs\"][i])\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in f[\"obs\"].keys():\n",
    "    print(i)\n",
    "    if i not in [\"Hispanic\", \"Race (choice=American Indian\", \"Race (choice=Black\", \"__categories\"]:\n",
    "        df[i] = np.array(f[\"obs\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0512b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147], dtype=int16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(f[\"obs\"][\"Supertype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bc69a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"obs_all-nuclei.2022-08-18.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
